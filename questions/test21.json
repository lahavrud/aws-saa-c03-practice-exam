[
  {
    "id": 0,
    "text": "A company needs a solution to enforce data encryption at rest on Amazon EC2 instances. The \nsolution must automatically identify noncompliant resources and enforce compliance policies on \nfindings. \n \nWhich solution will meet these requirements with the LEAST administrative overhead?",
    "options": [
      {
        "id": 0,
        "text": "Use an IAM policy that allows users to create only encrypted Amazon Elastic Block Store",
        "correct": true
      },
      {
        "id": 1,
        "text": "Use AWS Key Management Service (AWS KMS) to manage access to encrypted Amazon Elastic",
        "correct": false
      },
      {
        "id": 2,
        "text": "Use Amazon Macie to detect unencrypted Amazon Elastic Block Store (Amazon EBS) volumes.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Use Amazon inspector to detect unencrypted Amazon Elastic Block Store (Amazon EBS)",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "**Why option 0 is correct:**\nBy creating an IAM policy that allows users to create only encrypted EBS volumes, you proactively prevent the creation of unencrypted volumes. Using AWS Config, you can set up rules to detect noncompliant resources, and AWS Systems Manager Automation can be used for automated remediation. This approach provides a proactive and automated solution.\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 1,
    "text": "A company is migrating its multi-tier on-premises application to AWS. The application consists of \na single-node MySQL database and a multi-node web tier. The company must minimize changes \nto the application during the migration. The company wants to improve application resiliency after \nthe migration. \n \nWhich combination of steps will meet these requirements? (Choose two.)",
    "options": [
      {
        "id": 0,
        "text": "Migrate the web tier to Amazon EC2 instances in an Auto Scaling group behind an Application",
        "correct": true
      },
      {
        "id": 1,
        "text": "Migrate the database to Amazon EC2 instances in an Auto Scaling group behind a Network Load",
        "correct": false
      },
      {
        "id": 2,
        "text": "Migrate the database to an Amazon RDS Multi-AZ deployment.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Migrate the web tier to an AWS Lambda function.",
        "correct": false
      },
      {
        "id": 4,
        "text": "Migrate the database to an Amazon DynamoDB table.",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "**Why option 0 is correct:**\nWeb Tier Migration (Option A): Migrating the web tier to Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB) provides horizontal scalability, automatic scaling, and improved resiliency. Auto Scaling helps in managing and maintaining the desired number of EC2 instances based on demand, and the ALB distributes incoming traffic across multiple instances. Database Migration to Amazon RDS Multi-AZ (Option C): Migrating the database to Amazon RDS in a Multi-AZ deployment provides high availability and automatic failover. In a Multi-AZ deployment, Amazon RDS maintains a standby replica in a different Availability Zone, and in the event of a failure, it automatically promotes the replica to the primary instance. This enhances the resiliency of the database.\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 2,
    "text": "A company wants to migrate its web applications from on premises to AWS. The company is \nlocated close to the eu-central-1 Region. Because of regulations, the company cannot launch \nsome of its applications in eu-central-1. The company wants to achieve single-digit millisecond \nlatency. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Deploy the applications in eu-central-1. Extend the company's VPC from eu-central-1 to an edge",
        "correct": false
      },
      {
        "id": 1,
        "text": "Deploy the applications in AWS Local Zones by extending the company's VPC from eu-central-1",
        "correct": true
      },
      {
        "id": 2,
        "text": "Deploy the applications in eu-central-1. Extend the company's VPC from eu-central-1 to the",
        "correct": false
      },
      {
        "id": 3,
        "text": "Deploy the applications in AWS Wavelength Zones by extending the company's VPC from eu-",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "**Why option 1 is correct:**\nAWS Local Zones are a type of AWS infrastructure deployment that place compute, storage, database, and other select services closer to large population, industry, and IT centers, enabling you to deliver applications that require single-digit millisecond latency to end-users.\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 3,
    "text": "A company's ecommerce website has unpredictable traffic and uses AWS Lambda functions to \ndirectly access a private Amazon RDS for PostgreSQL DB instance. The company wants to \nmaintain predictable database performance and ensure that the Lambda invocations do not \noverload the database with too many connections. \n \nWhat should a solutions architect do to meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Point the client driver at an RDS custom endpoint. Deploy the Lambda functions inside a VPC.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions inside a VPC.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Point the client driver at an RDS custom endpoint. Deploy the Lambda functions outside a VPC.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions outside a VPC.",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 4,
    "text": "A company is creating an application. The company stores data from tests of the application in \nmultiple on-premises locations. \n \nThe company needs to connect the on-premises locations to VPCs in an AWS Region in the \nAWS Cloud. The number of accounts and VPCs will increase during the next year. The network \narchitecture must simplify the administration of new connections and must provide the ability to \nscale. \n \nWhich solution will meet these requirements with the LEAST administrative overhead?",
    "options": [
      {
        "id": 0,
        "text": "Create a peering connection between the VPCs. Create a VPN connection between the VPCs",
        "correct": false
      },
      {
        "id": 1,
        "text": "Launch an Amazon EC2 instance. On the instance, include VPN software that uses a VPN",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create a transit gateway. Create VPC attachments for the VPC connections. Create VPN",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create an AWS Direct Connect connection between the on-premises locations and a central",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 5,
    "text": "Get Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n373 \nA company that uses AWS needs a solution to predict the resources needed for manufacturing \nprocesses each month. The solution must use historical values that are currently stored in an \nAmazon S3 bucket. The company has no machine learning (ML) experience and wants to use a \nmanaged service for the training and predictions. \n \nWhich combination of steps will meet these requirements? (Choose two.)",
    "options": [
      {
        "id": 0,
        "text": "Deploy an Amazon SageMaker model. Create a SageMaker endpoint for inference.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use Amazon SageMaker to train a model by using the historical data in the S3 bucket.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Configure an AWS Lambda function with a function URL that uses Amazon SageMaker endpoints",
        "correct": false
      },
      {
        "id": 3,
        "text": "Configure an AWS Lambda function with a function URL that uses an Amazon Forecast predictor",
        "correct": false
      },
      {
        "id": 4,
        "text": "Train an Amazon Forsecast predictor by using the historical data in the S3 bucket.",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 6,
    "text": "A company manages AWS accounts in AWS Organizations. AWS IAM Identity Center (AWS \nSingle Sign-On) and AWS Control Tower are configured for the accounts. The company wants to \nmanage multiple user permissions across all the accounts. \n \nThe permissions will be used by multiple IAM users and must be split between the developer and \nadministrator teams. Each team requires different permissions. The company wants a solution \nthat includes new users that are hired on both teams. \n \nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Create individual users in IAM Identity Center for each account. Create separate developer and",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create individual users in IAM Identity Center for each account. Create separate developer and",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create individual users in IAM Identity Center. Create new developer and administrator groups in",
        "correct": true
      },
      {
        "id": 3,
        "text": "Create individual users in IAM Identity Center. Create new permission sets that include the",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "**Why option 2 is correct:**\nhttps://docs.aws.amazon.com/controltower/latest/userguide/sso.html\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 7,
    "text": "A company wants to standardize its Amazon Elastic Block Store (Amazon EBS) volume \nencryption strategy. The company also wants to minimize the cost and configuration effort \nrequired to operate the volume encryption check. \n \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n374 \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Write API calls to describe the EBS volumes and to confirm the EBS volumes are encrypted. Use",
        "correct": false
      },
      {
        "id": 1,
        "text": "Write API calls to describe the EBS volumes and to confirm the EBS volumes are encrypted. Run",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create an AWS Identity and Access Management (IAM) policy that requires the use of tags on",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create an AWS Config rule for Amazon EBS to evaluate if a volume is encrypted and to flag the",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "**Why option 3 is correct:**\nYou could use a managed rule to quickly start assessing whether your Amazon Elastic Block Store (Amazon EBS) volumes are encrypted or whether specific tags are applied to your resources. https://docs.aws.amazon.com/config/latest/developerguide/evaluate-config_use-managed- rules.html\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 8,
    "text": "A company regularly uploads GB-sized files to Amazon S3. After the company uploads the files, \nthe company uses a fleet of Amazon EC2 Spot Instances to transcode the file format. The \ncompany needs to scale throughput when the company uploads data from the on-premises data \ncenter to Amazon S3 and when the company downloads data from Amazon S3 to the EC2 \ninstances. \n \nWhich solutions will meet these requirements? (Choose two.)",
    "options": [
      {
        "id": 0,
        "text": "Use the S3 bucket access point instead of accessing the S3 bucket directly.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Upload the files into multiple S3 buckets.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Use S3 multipart uploads.",
        "correct": true
      },
      {
        "id": 3,
        "text": "Fetch multiple byte-ranges of an object in parallel.",
        "correct": false
      },
      {
        "id": 4,
        "text": "Add a random prefix to each object when uploading the files.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Cost-Optimized Architectures"
  },
  {
    "id": 10,
    "text": "A company is deploying an application in three AWS Regions using an Application Load \nBalancer. Amazon Route 53 will be used to distribute traffic between these Regions. \n \nWhich Route 53 configuration should a solutions architect use to provide the MOST high-\nperforming experience?",
    "options": [
      {
        "id": 0,
        "text": "Create an A record with a latency policy.",
        "correct": true
      },
      {
        "id": 1,
        "text": "Create an A record with a geolocation policy.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create a CNAME record with a failover policy.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create a CNAME record with a geoproximity policy.",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "**Why option 0 is correct:**\nLBR (Latency Based Routing) is a new feature for Amazon Route 53 that helps you improve your applicationâ€™s performance for a global audience. You can run applications in multiple AWS regions and Amazon Route 53, using dozens of edge locations worldwide, will route end users to the AWS region that provides the lowest latency. https://aws.amazon.com/route53/faqs/\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 11,
    "text": "A company has a web application that includes an embedded NoSQL database. The application \nruns on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in \nan Amazon EC2 Auto Scaling group in a single Availability Zone. \n \nA recent increase in traffic requires the application to be highly available and for the database to \nbe eventually consistent. \n \nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Replace the ALB with a Network Load Balancer. Maintain the embedded NoSQL database with",
        "correct": false
      },
      {
        "id": 1,
        "text": "Replace the ALB with a Network Load Balancer. Migrate the embedded NoSQL database to",
        "correct": false
      },
      {
        "id": 2,
        "text": "Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Maintain the",
        "correct": false
      },
      {
        "id": 3,
        "text": "Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Migrate the",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 12,
    "text": "A company is building a shopping application on AWS. The application offers a catalog that \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n376 \nchanges once each month and needs to scale with traffic volume. The company wants the lowest \npossible latency from the application. Data from each user's shopping cart needs to be highly \navailable. User session data must be available even if the user is disconnected and reconnects. \n \nWhat should a solutions architect do to ensure that the shopping cart data is preserved at all \ntimes?",
    "options": [
      {
        "id": 0,
        "text": "Configure an Application Load Balancer to enable the sticky sessions feature (session affinity) for",
        "correct": false
      },
      {
        "id": 1,
        "text": "Configure Amazon ElastiCache for Redis to cache catalog data from Amazon DynamoDB and",
        "correct": true
      },
      {
        "id": 2,
        "text": "Configure Amazon OpenSearch Service to cache catalog data from Amazon DynamoDB and",
        "correct": false
      },
      {
        "id": 3,
        "text": "Configure an Amazon EC2 instance with Amazon Elastic Block Store (Amazon EBS) storage for",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 13,
    "text": "A company is building a microservices-based application that will be deployed on Amazon Elastic \nKubernetes Service (Amazon EKS). The microservices will interact with each other. The company \nwants to ensure that the application is observable to identify performance issues in the future. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Configure the application to use Amazon ElastiCache to reduce the number of requests that are",
        "correct": false
      },
      {
        "id": 1,
        "text": "Configure Amazon CloudWatch Container Insights to collect metrics from the EKS clusters.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Configure AWS CloudTrail to review the API calls. Build an Amazon QuickSight dashboard to",
        "correct": false
      },
      {
        "id": 3,
        "text": "Use AWS Trusted Advisor to understand the performance of the application.",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "**Why option 1 is correct:**\nAmazon CloudWatch Container Insights: This service provides monitoring and troubleshooting capabilities for containerized applications. It collects and aggregates metrics, logs, and events from Amazon EKS clusters and containers. This helps in monitoring the performance and health of microservices.\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 14,
    "text": "A company needs to provide customers with secure access to its data. The company processes \ncustomer data and stores the results in an Amazon S3 bucket. \n \nAll the data is subject to strong regulations and security requirements. The data must be \nencrypted at rest. Each customer must be able to access only their data from their AWS account. \nCompany employees must not be able to access the data. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Provision an AWS Certificate Manager (ACM) certificate for each customer. Encrypt the data",
        "correct": false
      },
      {
        "id": 1,
        "text": "Provision a separate AWS Key Management Service (AWS KMS) key for each customer. Encrypt",
        "correct": false
      },
      {
        "id": 2,
        "text": "Provision a separate AWS Key Management Service (AWS KMS) key for each customer. Encrypt",
        "correct": true
      },
      {
        "id": 3,
        "text": "Provision an AWS Certificate Manager (ACM) certificate for each customer. Encrypt the data",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 15,
    "text": "A solutions architect creates a VPC that includes two public subnets and two private subnets. A \ncorporate security mandate requires the solutions architect to launch all Amazon EC2 instances \nin a private subnet. However, when the solutions architect launches an EC2 instance that runs a \nweb server on ports 80 and 443 in a private subnet, no external internet traffic can connect to the \nserver. \n \nWhat should the solutions architect do to resolve this issue?",
    "options": [
      {
        "id": 0,
        "text": "Attach the EC2 instance to an Auto Scaling group in a private subnet. Ensure that the DNS record",
        "correct": false
      },
      {
        "id": 1,
        "text": "Provision an internet-facing Application Load Balancer (ALB) in a public subnet. Add the EC2",
        "correct": true
      },
      {
        "id": 2,
        "text": "Launch a NAT gateway in a private subnet. Update the route table for the private subnets to add",
        "correct": false
      },
      {
        "id": 3,
        "text": "Ensure that the security group that is attached to the EC2 instance allows HTTP traffic on port 80",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 16,
    "text": "A company is deploying a new application to Amazon Elastic Kubernetes Service (Amazon EKS) \nwith an AWS Fargate cluster. The application needs a storage solution for data persistence. The \nsolution must be highly available and fault tolerant. The solution also must be shared between \nmultiple application containers. \n \nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Create Amazon Elastic Block Store (Amazon EBS) volumes in the same Availability Zones where",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create an Amazon Elastic File System (Amazon EFS) file system. Register the file system in a",
        "correct": true
      },
      {
        "id": 2,
        "text": "Create an Amazon Elastic Block Store (Amazon EBS) volume. Register the volume in a",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create Amazon Elastic File System (Amazon EFS) file systems in the same Availability Zones",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 17,
    "text": "A company has an application that uses Docker containers in its local data center. The \napplication runs on a container host that stores persistent data in a volume on the host. The \ncontainer instances use the stored persistent data. \n \nThe company wants to move the application to a fully managed service because the company \ndoes not want to manage any servers or storage infrastructure. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Use Amazon Elastic Kubernetes Service (Amazon EKS) with self-managed nodes. Create an",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create",
        "correct": true
      },
      {
        "id": 2,
        "text": "Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create",
        "correct": false
      },
      {
        "id": 3,
        "text": "Use Amazon Elastic Container Service (Amazon ECS) with an Amazon EC2 launch type. Create",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "**Why option 1 is correct:**\nMounting S3 in Fargate is not supported commonly. You'd have to make it manually. EFS is very well supported with Fargate. https://stackoverflow.com/\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 18,
    "text": "A gaming company wants to launch a new internet-facing application in multiple AWS Regions. \nThe application will use the TCP and UDP protocols for communication. The company needs to \nprovide high availability and minimum latency for global users. \n \nWhich combination of actions should a solutions architect take to meet these requirements? \n(Choose two.)",
    "options": [
      {
        "id": 0,
        "text": "Create internal Network Load Balancers in front of the application in each Region.",
        "correct": true
      },
      {
        "id": 1,
        "text": "Create external Application Load Balancers in front of the application in each Region.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create an AWS Global Accelerator accelerator to route traffic to the load balancers in each",
        "correct": false
      },
      {
        "id": 3,
        "text": "Configure Amazon Route 53 to use a geolocation routing policy to distribute the traffic.",
        "correct": false
      },
      {
        "id": 4,
        "text": "Configure Amazon CloudFront to handle the traffic and route requests to the application in each",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "**Why option 0 is correct:**\nGet Latest & Actual SAA-C03 Exam's\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 19,
    "text": "A city has deployed a web application running on Amazon EC2 instances behind an Application \nLoad Balancer (ALB). The application's users have reported sporadic performance, which \nappears to be related to DDoS attacks originating from random IP addresses. The city needs a \nsolution that requires minimal configuration changes and provides an audit trail for the DDoS \nsources. \n \nWhich solution meets these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Enable an AWS WAF web ACL on the ALB, and configure rules to block traffic from unknown",
        "correct": false
      },
      {
        "id": 1,
        "text": "Subscribe to Amazon Inspector. Engage the AWS DDoS Response Team (DRT) to integrate",
        "correct": false
      },
      {
        "id": 2,
        "text": "Subscribe to AWS Shield Advanced. Engage the AWS DDoS Response Team (DRT) to integrate",
        "correct": true
      },
      {
        "id": 3,
        "text": "Create an Amazon CloudFront distribution for the application, and set the ALB as the origin.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 20,
    "text": "A company copies 200 TB of data from a recent ocean survey onto AWS Snowball Edge Storage \nOptimized devices. The company has a high performance computing (HPC) cluster that is hosted \non AWS to look for oil and gas deposits. A solutions architect must provide the cluster with \nconsistent sub-millisecond latency and high-throughput access to the data on the Snowball Edge \nStorage Optimized devices. The company is sending the devices back to AWS. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an AWS Storage",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an Amazon FSx for",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create an Amazon S3 bucket and an Amazon Elastic File System (Amazon EFS) file system.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create an Amazon FSx for Lustre file system. Import the data directly into the FSx for Lustre file",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 21,
    "text": "Get Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n380 \nA company has NFS servers in an on-premises data center that need to periodically back up \nsmall amounts of data to Amazon S3. \n \nWhich solution meets these requirements and is MOST cost-effective?",
    "options": [
      {
        "id": 0,
        "text": "Set up AWS Glue to copy the data from the on-premises servers to Amazon S3.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Set up an AWS DataSync agent on the on-premises servers, and sync the data to Amazon S3.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Set up an SFTP sync using AWS Transfer for SFTP to sync data from on premises to Amazon",
        "correct": false
      },
      {
        "id": 3,
        "text": "Set up an AWS Direct Connect connection between the on-premises data center and a VPC, and",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Cost-Optimized Architectures"
  },
  {
    "id": 22,
    "text": "An online video game company must maintain ultra-low latency for its game servers. The game \nservers run on Amazon EC2 instances. The company needs a solution that can handle millions of \nUDP internet traffic requests each second. \n \nWhich solution will meet these requirements MOST cost-effectively?",
    "options": [
      {
        "id": 0,
        "text": "Configure an Application Load Balancer with the required protocol and ports for the internet",
        "correct": false
      },
      {
        "id": 1,
        "text": "Configure a Gateway Load Balancer for the internet traffic. Specify the EC2 instances as the",
        "correct": false
      },
      {
        "id": 2,
        "text": "Configure a Network Load Balancer with the required protocol and ports for the internet traffic.",
        "correct": true
      },
      {
        "id": 3,
        "text": "Launch an identical set of game servers on EC2 instances in separate AWS Regions. Route",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "**Why option 2 is correct:**\nhttps://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Cost-Optimized Architectures"
  },
  {
    "id": 23,
    "text": "A company runs a three-tier application in a VPC. The database tier uses an Amazon RDS for \nMySQL DB instance. \n \nThe company plans to migrate the RDS for MySQL DB instance to an Amazon Aurora \nPostgreSQL DB cluster. The company needs a solution that replicates the data changes that \nhappen during the migration to the new database. \n \nWhich combination of steps will meet these requirements? (Choose two.)",
    "options": [
      {
        "id": 0,
        "text": "Use AWS Database Migration Service (AWS DMS) Schema Conversion to transform the",
        "correct": true
      },
      {
        "id": 1,
        "text": "Use AWS Database Migration Service (AWS DMS) Schema Conversion to create an Aurora",
        "correct": false
      },
      {
        "id": 2,
        "text": "Configure an Aurora MySQL read replica for the RDS for MySQL DB instance.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Define an AWS Database Migration Service (AWS DMS) task with change data capture (CDC) to",
        "correct": false
      },
      {
        "id": 4,
        "text": "Promote the Aurora PostgreSQL read replica to a standalone Aurora PostgreSQL DB cluster",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 24,
    "text": "A company hosts a database that runs on an Amazon RDS instance that is deployed to multiple \nAvailability Zones. The company periodically runs a script against the database to report new \nentries that are added to the database. The script that runs against the database negatively \naffects the performance of a critical application. The company needs to improve application \nperformance with minimal costs. \n \nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Add functionality to the script to identify the instance that has the fewest active connections.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create a read replica of the database. Configure the script to query only the read replica to report",
        "correct": false
      },
      {
        "id": 2,
        "text": "Instruct the development team to manually export the new entries for the day in the database at",
        "correct": true
      },
      {
        "id": 3,
        "text": "Use Amazon ElastiCache to cache the common queries that the script runs against the database.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 25,
    "text": "A company is using an Application Load Balancer (ALB) to present its application to the internet. \nThe company finds abnormal traffic access patterns across the application. A solutions architect \nneeds to improve visibility into the infrastructure to help the company understand these \nabnormalities better. \n \nWhat is the MOST operationally efficient solution that meets these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Create a table in Amazon Athena for AWS CloudTrail logs. Create a query for the relevant",
        "correct": false
      },
      {
        "id": 1,
        "text": "Enable ALB access logging to Amazon S3. Create a table in Amazon Athena, and query the logs.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Enable ALB access logging to Amazon S3. Open each file in a text editor, and search each line",
        "correct": false
      },
      {
        "id": 3,
        "text": "Use Amazon EMR on a dedicated Amazon EC2 instance to directly query the ALB to acquire",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 26,
    "text": "A company wants to use NAT gateways in its AWS environment. The company's Amazon EC2 \ninstances in private subnets must be able to connect to the public internet through the NAT \ngateways. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Create public NAT gateways in the same private subnets as the EC2 instances.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create private NAT gateways in the same private subnets as the EC2 instances.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create public NAT gateways in public subnets in the same VPCs as the EC2 instances.",
        "correct": true
      },
      {
        "id": 3,
        "text": "Create private NAT gateways in public subnets in the same VPCs as the EC2 instances.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "**Why option 2 is correct:**\nPublic NAT GW in Public Subnet to have access to internet. Private NAT GW is used for VPC or on-prem.\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 27,
    "text": "A company has an organization in AWS Organizations. The company runs Amazon EC2 \ninstances across four AWS accounts in the root organizational unit (OU). There are three \nnonproduction accounts and one production account. The company wants to prohibit users from \nlaunching EC2 instances of a certain size in the nonproduction accounts. The company has \ncreated a service control policy (SCP) to deny access to launch instances that use the prohibited \ntypes. \n \nWhich solutions to deploy the SCP will meet these requirements? (Choose two.)",
    "options": [
      {
        "id": 0,
        "text": "Attach the SCP to the root OU for the organization.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Attach the SCP to the three nonproduction Organizations member accounts.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Attach the SCP to the Organizations management account.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create an OU for the production account. Attach the SCP to the OU. Move the production",
        "correct": false
      },
      {
        "id": 4,
        "text": "Create an OU for the required accounts. Attach the SCP to the OU. Move the nonproduction",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 28,
    "text": "A company's website hosted on Amazon EC2 instances processes classified data stored in \nAmazon S3. Due to security concerns, the company requires a private and secure connection \nbetween its EC2 resources and Amazon S3. \n \nWhich solution meets these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Set up S3 bucket policies to allow access from a VPC endpoint.",
        "correct": true
      },
      {
        "id": 1,
        "text": "Set up an IAM policy to grant read-write access to the S3 bucket.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Set up a NAT gateway to access resources outside the private subnet.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Set up an access key ID and a secret access key to access the S3 bucket.",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "**Why option 0 is correct:**\nA VPC endpoint enables customers to privately connect to supported AWS services.\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 29,
    "text": "An ecommerce company runs its application on AWS. The application uses an Amazon Aurora \nPostgreSQL cluster in Multi-AZ mode for the underlying database. During a recent promotional \ncampaign, the application experienced heavy read load and write load. Users experienced \ntimeout issues when they attempted to access the application. \n \nA solutions architect needs to make the application architecture more scalable and highly \navailable. \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n383 \n \nWhich solution will meet these requirements with the LEAST downtime?",
    "options": [
      {
        "id": 0,
        "text": "Create an Amazon EventBridge rule that has the Aurora cluster as a source. Create an AWS",
        "correct": false
      },
      {
        "id": 1,
        "text": "Modify the Aurora cluster and activate the zero-downtime restart (ZDR) feature. Use Database",
        "correct": false
      },
      {
        "id": 2,
        "text": "Add additional reader instances to the Aurora cluster. Create an Amazon RDS Proxy target group",
        "correct": true
      },
      {
        "id": 3,
        "text": "Create an Amazon ElastiCache for Redis cache. Replicate data from the Aurora cluster to Redis",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 30,
    "text": "A company is designing a web application on AWS. The application will use a VPN connection \nbetween the company's existing data centers and the company's VPCs. \n \nThe company uses Amazon Route 53 as its DNS service. The application must use private DNS \nrecords to communicate with the on-premises services from a VPC. \n \nWhich solution will meet these requirements in the MOST secure manner?",
    "options": [
      {
        "id": 0,
        "text": "Create a Route 53 Resolver outbound endpoint. Create a resolver rule. Associate the resolver",
        "correct": true
      },
      {
        "id": 1,
        "text": "Create a Route 53 Resolver inbound endpoint. Create a resolver rule. Associate the resolver rule",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create a Route 53 private hosted zone. Associate the private hosted zone with the VPC.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create a Route 53 public hosted zone. Create a record for each service to allow service",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 31,
    "text": "A company is running a photo hosting service in the us-east-1 Region. The service enables users \nacross multiple countries to upload and view photos. Some photos are heavily viewed for months, \nand others are viewed for less than a week. The application allows uploads of up to 20 MB for \neach photo. The service uses the photo metadata to determine which photos to display to each \nuser. \n \nWhich solution provides the appropriate user access MOST cost-effectively?",
    "options": [
      {
        "id": 0,
        "text": "Store the photos in Amazon DynamoDB. Turn on DynamoDB Accelerator (DAX) to cache",
        "correct": false
      },
      {
        "id": 1,
        "text": "Store the photos in the Amazon S3 Intelligent-Tiering storage class. Store the photo metadata",
        "correct": false
      },
      {
        "id": 2,
        "text": "Store the photos in the Amazon S3 Standard storage class. Set up an S3 Lifecycle policy to move",
        "correct": false
      },
      {
        "id": 3,
        "text": "Store the photos in the Amazon S3 Glacier storage class. Set up an S3 Lifecycle policy to move",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Cost-Optimized Architectures"
  },
  {
    "id": 32,
    "text": "A company runs a highly available web application on Amazon EC2 instances behind an \nApplication Load Balancer. The company uses Amazon CloudWatch metrics. \n \nAs the traffic to the web application increases, some EC2 instances become overloaded with \nmany outstanding requests. The CloudWatch metrics show that the number of requests \nprocessed and the time to receive the responses from some EC2 instances are both higher \ncompared to other EC2 instances. The company does not want new requests to be forwarded to \nthe EC2 instances that are already overloaded. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Use the round robin routing algorithm based on the RequestCountPerTarget and",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use the least outstanding requests algorithm based on the RequestCountPerTarget and",
        "correct": true
      },
      {
        "id": 2,
        "text": "Use the round robin routing algorithm based on the RequestCount and TargetResponseTime",
        "correct": false
      },
      {
        "id": 3,
        "text": "Use the least outstanding requests algorithm based on the RequestCount and",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 33,
    "text": "A company uses Amazon EC2, AWS Fargate, and AWS Lambda to run multiple workloads in the \ncompany's AWS account. The company wants to fully make use of its Compute Savings Plans. \nThe company wants to receive notification when coverage of the Compute Savings Plans drops. \n \nWhich solution will meet these requirements with the MOST operational efficiency?",
    "options": [
      {
        "id": 0,
        "text": "Create a daily budget for the Savings Plans by using AWS Budgets. Configure the budget with a",
        "correct": true
      },
      {
        "id": 1,
        "text": "Create a Lambda function that runs a coverage report against the Savings Plans. Use Amazon",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create an AWS Budgets report for the Savings Plans budget. Set the frequency to daily.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create a Savings Plans alert subscription. Enable all notification options. Enter an email address",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "**Why option 0 is correct:**\nhttps://docs.aws.amazon.com/savingsplans/latest/userguide/sp-usingBudgets.html\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Cost-Optimized Architectures"
  },
  {
    "id": 34,
    "text": "A company runs a real-time data ingestion solution on AWS. The solution consists of the most \nrecent version of Amazon Managed Streaming for Apache Kafka (Amazon MSK). The solution is \ndeployed in a VPC in private subnets across three Availability Zones. \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n385 \n \nA solutions architect needs to redesign the data ingestion solution to be publicly available over \nthe internet. The data in transit must also be encrypted. \n \nWhich solution will meet these requirements with the MOST operational efficiency?",
    "options": [
      {
        "id": 0,
        "text": "Configure public subnets in the existing VPC. Deploy an MSK cluster in the public subnets.",
        "correct": true
      },
      {
        "id": 1,
        "text": "Create a new VPC that has public subnets. Deploy an MSK cluster in the public subnets. Update",
        "correct": false
      },
      {
        "id": 2,
        "text": "Deploy an Application Load Balancer (ALB) that uses private subnets. Configure an ALB security",
        "correct": false
      },
      {
        "id": 3,
        "text": "Deploy a Network Load Balancer (NLB) that uses private subnets. Configure an NLB listener for",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 35,
    "text": "A company wants to migrate an on-premises legacy application to AWS. The application ingests \ncustomer order files from an on-premises enterprise resource planning (ERP) system. The \napplication then uploads the files to an SFTP server. The application uses a scheduled job that \nchecks for order files every hour. \n \nThe company already has an AWS account that has connectivity to the on-premises network. The \nnew application on AWS must support integration with the existing ERP system. The new \napplication must be secure and resilient and must use the SFTP protocol to process orders from \nthe ERP system immediately. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Create an AWS Transfer Family SFTP internet-facing server in two Availability Zones. Use",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create an AWS Transfer Family SFTP internet-facing server in one Availability Zone. Use",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon S3",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 36,
    "text": "A company's applications use Apache Hadoop and Apache Spark to process data on premises. \nThe existing infrastructure is not scalable and is complex to manage. \n \nA solutions architect must design a scalable solution that reduces operational complexity. The \nsolution must keep the data processing on premises. \n \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n386 \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Use AWS Site-to-Site VPN to access the on-premises Hadoop Distributed File System (HDFS)",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use AWS DataSync to connect to the on-premises Hadoop Distributed File System (HDFS)",
        "correct": false
      },
      {
        "id": 2,
        "text": "Migrate the Apache Hadoop application and the Apache Spark application to Amazon EMR",
        "correct": true
      },
      {
        "id": 3,
        "text": "Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Create an Amazon",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 37,
    "text": "A company is migrating a large amount of data from on-premises storage to AWS. Windows, \nMac, and Linux based Amazon EC2 instances in the same AWS Region will access the data by \nusing SMB and NFS storage protocols. The company will access a portion of the data routinely. \nThe company will access the remaining data infrequently. \n \nThe company needs to design a solution to host the data. \n \nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Create an Amazon Elastic File System (Amazon EFS) volume that uses EFS Intelligent-Tiering.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create an Amazon FSx for ONTAP instance. Create an FSx for ONTAP file system with a root",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create an Amazon S3 bucket that uses S3 Intelligent-Tiering. Migrate the data to the S3 bucket",
        "correct": true
      },
      {
        "id": 3,
        "text": "Create an Amazon FSx for OpenZFS file system. Migrate the data to the new volume.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 38,
    "text": "A manufacturing company runs its report generation application on AWS. The application \ngenerates each report in about 20 minutes. The application is built as a monolith that runs on a \nsingle Amazon EC2 instance. The application requires frequent updates to its tightly coupled \nmodules. The application becomes complex to maintain as the company adds new features. \n \nEach time the company patches a software module, the application experiences downtime. \nReport generation must restart from the beginning after any interruptions. The company wants to \nredesign the application so that the application can be flexible, scalable, and gradually improved. \nThe company wants to minimize application downtime. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Run the application on AWS Lambda as a single function with maximum provisioned",
        "correct": false
      },
      {
        "id": 1,
        "text": "Run the application on Amazon EC2 Spot Instances as microservices with a Spot Fleet default",
        "correct": true
      },
      {
        "id": 2,
        "text": "Run the application on Amazon Elastic Container Service (Amazon ECS) as microservices with",
        "correct": false
      },
      {
        "id": 3,
        "text": "Run the application on AWS Elastic Beanstalk as a single application environment with an all-at-",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 39,
    "text": "A company wants to rearchitect a large-scale web application to a serverless microservices \narchitecture. The application uses Amazon EC2 instances and is written in Python. \n \nThe company selected one component of the web application to test as a microservice. The \ncomponent supports hundreds of requests each second. The company wants to create and test \nthe microservice on an AWS solution that supports Python. The solution must also scale \nautomatically and require minimal infrastructure and minimal operational support. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Use a Spot Fleet with auto scaling of EC2 instances that run the most recent Amazon Linux",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use an AWS Elastic Beanstalk web server environment that has high availability configured.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Use Amazon Elastic Kubernetes Service (Amazon EKS). Launch Auto Scaling groups of self-",
        "correct": true
      },
      {
        "id": 3,
        "text": "Use an AWS Lambda function that runs custom developed code.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 40,
    "text": "A company has an AWS Direct Connect connection from its on-premises location to an AWS \naccount. The AWS account has 30 different VPCs in the same AWS Region. The VPCs use \nprivate virtual interfaces (VIFs). Each VPC has a CIDR block that does not overlap with other \nnetworks under the company's control. \n \nThe company wants to centrally manage the networking architecture while still allowing each VPC \nto communicate with all other VPCs and on-premises networks. \n \nWhich solution will meet these requirements with the LEAST amount of operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Create a transit gateway, and associate the Direct Connect connection with a new transit VIF.",
        "correct": true
      },
      {
        "id": 1,
        "text": "Create a Direct Connect gateway. Recreate the private VIFs to use the new gateway. Associate",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create a transit VPConnect the Direct Connect connection to the transit VPCreate a peering",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create AWS Site-to-Site VPN connections from on premises to each VPC. Ensure that both VPN",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 41,
    "text": "A company has applications that run on Amazon EC2 instances. The EC2 instances connect to \nAmazon RDS databases by using an IAM role that has associated policies. The company wants \nto use AWS Systems Manager to patch the EC2 instances without disrupting the running \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n388 \napplications. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Create a new IAM role. Attach the AmazonSSMManagedInstanceCore policy to the new IAM role.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create an IAM user. Attach the AmazonSSMManagedInstanceCore policy to the IAM user.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Enable Default Host Configuration Management in Systems Manager to manage the EC2",
        "correct": true
      },
      {
        "id": 3,
        "text": "Remove the existing policies from the existing IAM role. Add the",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 42,
    "text": "A company runs container applications by using Amazon Elastic Kubernetes Service (Amazon \nEKS) and the Kubernetes Horizontal Pod Autoscaler. The workload is not consistent throughout \nthe day. A solutions architect notices that the number of nodes does not automatically scale out \nwhen the existing nodes have reached maximum capacity in the cluster, which causes \nperformance issues. \n \nWhich solution will resolve this issue with the LEAST administrative overhead?",
    "options": [
      {
        "id": 0,
        "text": "Scale out the nodes by tracking the memory usage.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use the Kubernetes Cluster Autoscaler to manage the number of nodes in the cluster.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Use an AWS Lambda function to resize the EKS cluster automatically.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Use an Amazon EC2 Auto Scaling group to distribute the workload.",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 43,
    "text": "A company maintains about 300 TB in Amazon S3 Standard storage month after month. The S3 \nobjects are each typically around 50 GB in size and are frequently replaced with multipart uploads \nby their global application. The number and size of S3 objects remain constant, but the \ncompany's S3 storage costs are increasing each month. \n \nHow should a solutions architect reduce costs in this situation?",
    "options": [
      {
        "id": 0,
        "text": "Switch from multipart uploads to Amazon S3 Transfer Acceleration.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Enable an S3 Lifecycle policy that deletes incomplete multipart uploads.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Configure S3 inventory to prevent objects from being archived too quickly.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Configure Amazon CloudFront to reduce the number of objects stored in Amazon S3.",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Cost-Optimized Architectures"
  },
  {
    "id": 44,
    "text": "A company has deployed a multiplayer game for mobile devices. The game requires live location \ntracking of players based on latitude and longitude. The data store for the game must support \nrapid updates and retrieval of locations. \n \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n389 \nThe game uses an Amazon RDS for PostgreSQL DB instance with read replicas to store the \nlocation data. During peak usage periods, the database is unable to maintain the performance \nthat is needed for reading and writing updates. The game's user base is increasing rapidly. \n \nWhat should a solutions architect do to improve the performance of the data tier?",
    "options": [
      {
        "id": 0,
        "text": "Take a snapshot of the existing DB instance. Restore the snapshot with Multi-AZ enabled.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Migrate from Amazon RDS to Amazon OpenSearch Service with OpenSearch Dashboards.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Deploy Amazon DynamoDB Accelerator (DAX) in front of the existing DB instance. Modify the",
        "correct": false
      },
      {
        "id": 3,
        "text": "Deploy an Amazon ElastiCache for Redis cluster in front of the existing DB instance. Modify the",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 45,
    "text": "A company stores critical data in Amazon DynamoDB tables in the company's AWS account. An \nIT administrator accidentally deleted a DynamoDB table. The deletion caused a significant loss of \ndata and disrupted the company's operations. The company wants to prevent this type of \ndisruption in the future. \n \nWhich solution will meet this requirement with the LEAST operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Configure a trail in AWS CloudTrail. Create an Amazon EventBridge rule for delete actions.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create a backup and restore plan for the DynamoDB tables. Recover the DynamoDB tables",
        "correct": false
      },
      {
        "id": 2,
        "text": "Configure deletion protection on the DynamoDB tables.",
        "correct": true
      },
      {
        "id": 3,
        "text": "Enable point-in-time recovery on the DynamoDB tables.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 47,
    "text": "A company runs a three-tier web application in a VPC across multiple Availability Zones. Amazon \nEC2 instances run in an Auto Scaling group for the application tier. \n \nThe company needs to make an automated scaling plan that will analyze each resource's daily \nand weekly historical workload trends. The configuration must scale resources appropriately \naccording to both the forecast and live changes in utilization. \n \nWhich scaling strategy should a solutions architect recommend to meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Implement dynamic scaling with step scaling based on average CPU utilization from the EC2",
        "correct": false
      },
      {
        "id": 1,
        "text": "Enable predictive scaling to forecast and scale. Configure dynamic scaling with target tracking",
        "correct": true
      },
      {
        "id": 2,
        "text": "Create an automated scheduled scaling action based on the traffic patterns of the web",
        "correct": false
      },
      {
        "id": 3,
        "text": "Set up a simple scaling policy. Increase the cooldown period based on the EC2 instance startup",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 48,
    "text": "A package delivery company has an application that uses Amazon EC2 instances and an \nAmazon Aurora MySQL DB cluster. As the application becomes more popular, EC2 instance \nusage increases only slightly. DB cluster usage increases at a much faster rate. \n \nThe company adds a read replica, which reduces the DB cluster usage for a short period of time. \nHowever, the load continues to increase. The operations that cause the increase in DB cluster \nusage are all repeated read statements that are related to delivery details. The company needs to \nalleviate the effect of repeated reads on the DB cluster. \n \nWhich solution will meet these requirements MOST cost-effectively?",
    "options": [
      {
        "id": 0,
        "text": "Implement an Amazon ElastiCache for Redis cluster between the application and the DB cluster.",
        "correct": true
      },
      {
        "id": 1,
        "text": "Add an additional read replica to the DB cluster.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Configure Aurora Auto Scaling for the Aurora read replicas.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Modify the DB cluster to have multiple writer instances.",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 49,
    "text": "A company has an application that uses an Amazon DynamoDB table for storage. A solutions \narchitect discovers that many requests to the table are not returning the latest data. The \ncompany's users have not reported any other issues with database performance. Latency is in an \nacceptable range. \n \nWhich design change should the solutions architect recommend?",
    "options": [
      {
        "id": 0,
        "text": "Add read replicas to the table.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use a global secondary index (GSI).",
        "correct": false
      },
      {
        "id": 2,
        "text": "Request strongly consistent reads for the table.",
        "correct": true
      },
      {
        "id": 3,
        "text": "Request eventually consistent reads for the table.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 50,
    "text": "A company has deployed its application on Amazon EC2 instances with an Amazon RDS \ndatabase. The company used the principle of least privilege to configure the database access \ncredentials. The company's security team wants to protect the application and the database from \nSQL injection and other web-based attacks. \n \nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Use security groups and network ACLs to secure the database and application servers.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use AWS WAF to protect the application. Use RDS parameter groups to configure the security",
        "correct": true
      },
      {
        "id": 2,
        "text": "Use AWS Network Firewall to protect the application and the database.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Use different database accounts in the application code for different functions. Avoid granting",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 51,
    "text": "An ecommerce company runs applications in AWS accounts that are part of an organization in \nAWS Organizations. The applications run on Amazon Aurora PostgreSQL databases across all \nthe accounts. The company needs to prevent malicious activity and must identify abnormal failed \nand incomplete login attempts to the databases. \n \nWhich solution will meet these requirements in the MOST operationally efficient way?",
    "options": [
      {
        "id": 0,
        "text": "Attach service control policies (SCPs) to the root of the organization to identity the failed login",
        "correct": false
      },
      {
        "id": 1,
        "text": "Enable the Amazon RDS Protection feature in Amazon GuardDuty for the member accounts of",
        "correct": true
      },
      {
        "id": 2,
        "text": "Publish the Aurora general logs to a log group in Amazon CloudWatch Logs. Export the log data",
        "correct": false
      },
      {
        "id": 3,
        "text": "Publish all the Aurora PostgreSQL database events in AWS CloudTrail to a central Amazon S3",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 52,
    "text": "A company has an AWS Direct Connect connection from its corporate data center to its VPC in \nthe us-east-1 Region. The company recently acquired a corporation that has several VPCs and a \nDirect Connect connection between its on-premises data center and the eu-west-2 Region. The \nCIDR blocks for the VPCs of the company and the corporation do not overlap. The company \nrequires connectivity between two Regions and the data centers. The company needs a solution \nthat is scalable while reducing operational overhead. \n \nWhat should a solutions architect do to meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Set up inter-Region VPC peering between the VPC in us-east-1 and the VPCs in eu-west-2.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create private virtual interfaces from the Direct Connect connection in us-east-1 to the VPCs in",
        "correct": false
      },
      {
        "id": 2,
        "text": "Establish VPN appliances in a fully meshed VPN network hosted by Amazon EC2. Use AWS",
        "correct": false
      },
      {
        "id": 3,
        "text": "Connect the existing Direct Connect connection to a Direct Connect gateway. Route traffic from",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Resilient Architectures"
  },
  {
    "id": 54,
    "text": "A company has multiple AWS accounts with applications deployed in the us-west-2 Region. \nApplication logs are stored within Amazon S3 buckets in each account. The company wants to \nbuild a centralized log analysis solution that uses a single S3 bucket. Logs must not leave us-\nwest-2, and the company wants to incur minimal operational overhead. \n \nWhich solution meets these requirements and is MOST cost-effective?",
    "options": [
      {
        "id": 0,
        "text": "Create an S3 Lifecycle policy that copies the objects from one of the application S3 buckets to the",
        "correct": false
      },
      {
        "id": 1,
        "text": "Use S3 Same-Region Replication to replicate logs from the S3 buckets to another S3 bucket in",
        "correct": true
      },
      {
        "id": 2,
        "text": "Write a script that uses the PutObject API operation every day to copy the entire contents of the",
        "correct": false
      },
      {
        "id": 3,
        "text": "Write AWS Lambda functions in these accounts that are triggered every time logs are delivered to",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Cost-Optimized Architectures"
  },
  {
    "id": 55,
    "text": "Get Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n393 \nA company has an application that delivers on-demand training videos to students around the \nworld. The application also allows authorized content developers to upload videos. The data is \nstored in an Amazon S3 bucket in the us-east-2 Region. \n \nThe company has created an S3 bucket in the eu-west-2 Region and an S3 bucket in the ap-\nsoutheast-1 Region. The company wants to replicate the data to the new S3 buckets. The \ncompany needs to minimize latency for developers who upload videos and students who stream \nvideos near eu-west-2 and ap-southeast-1. \n \nWhich combination of steps will meet these requirements with the FEWEST changes to the \napplication? (Choose two.)",
    "options": [
      {
        "id": 0,
        "text": "Configure one-way replication from the us-east-2 S3 bucket to the eu-west-2 S3 bucket.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Configure one-way replication from the us-east-2 S3 bucket to the eu-west-2 S3 bucket.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Configure two-way (bidirectional) replication among the S3 buckets that are in all three Regions.",
        "correct": true
      },
      {
        "id": 3,
        "text": "Create an S3 Multi-Region Access Point. Modify the application to use the Amazon Resource",
        "correct": false
      },
      {
        "id": 4,
        "text": "Create an S3 Multi-Region Access Point. Modify the application to use the Amazon Resource",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 56,
    "text": "A company has a new mobile app. Anywhere in the world, users can see local news on topics \nthey choose. Users also can post photos and videos from inside the app. \n \nUsers access content often in the first minutes after the content is posted. New content quickly \nreplaces older content, and then the older content disappears. The local nature of the news \nmeans that users consume 90% of the content within the AWS Region where it is uploaded. \n \nWhich solution will optimize the user experience by providing the LOWEST latency for content \nuploads?",
    "options": [
      {
        "id": 0,
        "text": "Upload and store content in Amazon S3. Use Amazon CloudFront for the uploads.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Upload and store content in Amazon S3. Use S3 Transfer Acceleration for the uploads.",
        "correct": true
      },
      {
        "id": 2,
        "text": "Upload content to Amazon EC2 instances in the Region that is closest to the user. Copy the data",
        "correct": false
      },
      {
        "id": 3,
        "text": "Upload and store content in Amazon S3 in the Region that is closest to the user. Use multiple",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 57,
    "text": "A company is building a new application that uses serverless architecture. The architecture will \nconsist of an Amazon API Gateway REST API and AWS Lambda functions to manage incoming \nrequests. \n \nThe company wants to add a service that can send messages received from the API Gateway \nREST API to multiple target Lambda functions for processing. The service must offer message \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n394 \nfiltering that gives the target Lambda functions the ability to receive only the messages the \nfunctions need. \n \nWhich solution will meet these requirements with the LEAST operational overhead?",
    "options": [
      {
        "id": 0,
        "text": "Send the requests from the API Gateway REST API to an Amazon Simple Notification Service",
        "correct": true
      },
      {
        "id": 1,
        "text": "Send the requests from the API Gateway REST API to Amazon EventBridge. Configure",
        "correct": false
      },
      {
        "id": 2,
        "text": "Send the requests from the API Gateway REST API to Amazon Managed Streaming for Apache",
        "correct": false
      },
      {
        "id": 3,
        "text": "Send the requests from the API Gateway REST API to multiple Amazon Simple Queue Service",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 58,
    "text": "A company migrated millions of archival files to Amazon S3. A solutions architect needs to \nimplement a solution that will encrypt all the archival data by using a customer-provided key. The \nsolution must encrypt existing unencrypted objects and future objects. \n \nWhich solution will meet these requirements?",
    "options": [
      {
        "id": 0,
        "text": "Create a list of unencrypted objects by filtering an Amazon S3 Inventory report. Configure an S3",
        "correct": true
      },
      {
        "id": 1,
        "text": "Use S3 Storage Lens metrics to identify unencrypted S3 buckets. Configure the S3 default",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create a list of unencrypted objects by filtering the AWS usage report for Amazon S3. Configure",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create a list of unencrypted objects by filtering the AWS usage report for Amazon S3. Configure",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "**Why option 0 is correct:**\nhttps://aws.amazon.com/blogs/storage/encrypting-objects-with-amazon-s3-batch-operations/\n\n**Why other options are incorrect:**\nThe other options do not meet the requirements specified in the scenario.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 59,
    "text": "The DNS provider that hosts a company's domain name records is experiencing outages that \ncause service disruption for a website running on AWS. The company needs to migrate to a more \nresilient managed DNS service and wants the service to run on AWS. \n \nWhat should a solutions architect do to rapidly migrate the DNS hosting service?",
    "options": [
      {
        "id": 0,
        "text": "Create an Amazon Route 53 public hosted zone for the domain name. Import the zone file",
        "correct": true
      },
      {
        "id": 1,
        "text": "Create an Amazon Route 53 private hosted zone for the domain name. Import the zone file",
        "correct": false
      },
      {
        "id": 2,
        "text": "Create a Simple AD directory in AWS. Enable zone transfer between the DNS provider and AWS",
        "correct": false
      },
      {
        "id": 3,
        "text": "Create an Amazon Route 53 Resolver inbound endpoint in the VPC. Specify the IP addresses",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 60,
    "text": "A company is building an application on AWS that connects to an Amazon RDS database. The \ncompany wants to manage the application configuration and to securely store and retrieve \ncredentials for the database and other services. \n \nWhich solution will meet these requirements with the LEAST administrative overhead?",
    "options": [
      {
        "id": 0,
        "text": "Use AWS AppConfig to store and manage the application configuration. Use AWS Secrets",
        "correct": true
      },
      {
        "id": 1,
        "text": "Use AWS Lambda to store and manage the application configuration. Use AWS Systems",
        "correct": false
      },
      {
        "id": 2,
        "text": "Use an encrypted application configuration file. Store the file in Amazon S3 for the application",
        "correct": false
      },
      {
        "id": 3,
        "text": "Use AWS AppConfig to store and manage the application configuration. Use Amazon RDS to",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  },
  {
    "id": 61,
    "text": "To meet security requirements, a company needs to encrypt all of its application data in transit \nwhile communicating with an Amazon RDS MySQL DB instance. A recent security audit revealed \nthat encryption at rest is enabled using AWS Key Management Service (AWS KMS), but data in \ntransit is not enabled. \n \nWhat should a solutions architect do to satisfy the security requirements?",
    "options": [
      {
        "id": 0,
        "text": "Enable IAM database authentication on the database.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Provide self-signed certificates. Use the certificates in all connections to the RDS instance.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Take a snapshot of the RDS instance. Restore the snapshot to a new instance with encryption",
        "correct": false
      },
      {
        "id": 3,
        "text": "Download AWS-provided root certificates. Provide the certificates in all connections to the RDS",
        "correct": true
      }
    ],
    "correctAnswers": [
      3
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 62,
    "text": "A company is designing a new web service that will run on Amazon EC2 instances behind an \nElastic Load Balancing (ELB) load balancer. However, many of the web service clients can only \nreach IP addresses authorized on their firewalls. \n \nWhat should a solutions architect recommend to meet the clients' needs? \n\n \n                                                                                \nGet Latest & Actual SAA-C03 Exam's Question and Answers from Passleader.                                 \nhttps://www.passleader.com  \n396",
    "options": [
      {
        "id": 0,
        "text": "A Network Load Balancer with an associated Elastic IP address.",
        "correct": false
      },
      {
        "id": 1,
        "text": "An Application Load Balancer with an associated Elastic IP address.",
        "correct": false
      },
      {
        "id": 2,
        "text": "An A record in an Amazon Route 53 hosted zone pointing to an Elastic IP address.",
        "correct": true
      },
      {
        "id": 3,
        "text": "An EC2 instance with a public IP address running as a proxy in front of the load balancer.",
        "correct": false
      }
    ],
    "correctAnswers": [
      2
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 63,
    "text": "A company has established a new AWS account. The account is newly provisioned and no \nchanges have been made to the default settings. The company is concerned about the security of \nthe AWS account root user. \n \nWhat should be done to secure the root user?",
    "options": [
      {
        "id": 0,
        "text": "Create IAM users for daily administrative tasks. Disable the root user.",
        "correct": false
      },
      {
        "id": 1,
        "text": "Create IAM users for daily administrative tasks. Enable multi-factor authentication on the root",
        "correct": true
      },
      {
        "id": 2,
        "text": "Generate an access key for the root user. Use the access key for daily administration tasks",
        "correct": false
      },
      {
        "id": 3,
        "text": "Provide the root user credentials to the most senior solutions architect. Have the solutions",
        "correct": false
      }
    ],
    "correctAnswers": [
      1
    ],
    "explanation": "Explanation not available.",
    "domain": "Design Secure Architectures"
  },
  {
    "id": 64,
    "text": "A company is deploying an application that processes streaming data in near-real time. The \ncompany plans to use Amazon EC2 instances for the workload. The network architecture must be \nconfigurable to provide the lowest possible latency between nodes. \n \nWhich combination of network solutions will meet these requirements? (Choose two.)",
    "options": [
      {
        "id": 0,
        "text": "Enable and configure enhanced networking on each EC2 instance.",
        "correct": true
      },
      {
        "id": 1,
        "text": "Group the EC2 instances in separate accounts.",
        "correct": false
      },
      {
        "id": 2,
        "text": "Run the EC2 instances in a cluster placement group.",
        "correct": false
      },
      {
        "id": 3,
        "text": "Attach multiple elastic network interfaces to each EC2 instance.",
        "correct": false
      },
      {
        "id": 4,
        "text": "Use Amazon Elastic Block Store (Amazon EBS) optimized instance types.",
        "correct": false
      }
    ],
    "correctAnswers": [
      0
    ],
    "explanation": "Explanation not available.",
    "domain": "Design High-Performing Architectures"
  }
]